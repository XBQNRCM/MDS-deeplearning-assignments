{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This code baseline is inspired by and modified from [this great tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "This code can achieve an accuracy of approximately 86.50% on CIFAR-10. Please set up the environment and run your experiments starting from this baseline. You are expected to achieve an accuracy higher than this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import some necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as tv_datasets\n",
    "import torchvision.transforms as tv_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some experimental setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 128\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "print_every = 200\n",
    "\n",
    "optim_name = \"Adam\"\n",
    "optim_kwargs = dict(\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-6,\n",
    ")\n",
    "\n",
    "# preprocessing pipeline for input images\n",
    "transformation = dict()\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    transformation[data_type] = tv_transforms.Compose(\n",
    "        (\n",
    "            [\n",
    "                tv_transforms.RandomRotation(degrees=15),\n",
    "                tv_transforms.RandomHorizontalFlip(),\n",
    "                tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            ] if is_train else []\n",
    "        ) + \n",
    "        [\n",
    "            tv_transforms.ToTensor(),\n",
    "            tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare datasets\n",
    "dataset, loader = {}, {}\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    dataset[data_type] = tv_datasets.CIFAR10(\n",
    "        root=\"./data\", train=is_train, download=True, transform=transformation[data_type],\n",
    "    )\n",
    "    loader[data_type] = torch.utils.data.DataLoader(\n",
    "        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 7.28M\n"
     ]
    }
   ],
   "source": [
    "# our network architecture\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(128, 10),\n",
    ")\n",
    "\n",
    "# move to device\n",
    "net.to(device)\n",
    "\n",
    "# print the number of parameters\n",
    "print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch=  1, iter=  200] loss: 2.180\n",
      "[epoch=  1, iter=  400] loss: 1.950\n",
      "[epoch=  1, iter=  600] loss: 1.825\n",
      "[epoch=  2, iter=  200] loss: 1.674\n",
      "[epoch=  2, iter=  400] loss: 1.587\n",
      "[epoch=  2, iter=  600] loss: 1.514\n",
      "[epoch=  3, iter=  200] loss: 1.429\n",
      "[epoch=  3, iter=  400] loss: 1.400\n",
      "[epoch=  3, iter=  600] loss: 1.346\n",
      "[epoch=  4, iter=  200] loss: 1.268\n",
      "[epoch=  4, iter=  400] loss: 1.252\n",
      "[epoch=  4, iter=  600] loss: 1.212\n",
      "[epoch=  5, iter=  200] loss: 1.163\n",
      "[epoch=  5, iter=  400] loss: 1.126\n",
      "[epoch=  5, iter=  600] loss: 1.106\n",
      "[epoch=  6, iter=  200] loss: 1.080\n",
      "[epoch=  6, iter=  400] loss: 1.055\n",
      "[epoch=  6, iter=  600] loss: 1.069\n",
      "[epoch=  7, iter=  200] loss: 1.006\n",
      "[epoch=  7, iter=  400] loss: 1.016\n",
      "[epoch=  7, iter=  600] loss: 0.975\n",
      "[epoch=  8, iter=  200] loss: 0.958\n",
      "[epoch=  8, iter=  400] loss: 0.944\n",
      "[epoch=  8, iter=  600] loss: 0.932\n",
      "[epoch=  9, iter=  200] loss: 0.894\n",
      "[epoch=  9, iter=  400] loss: 0.892\n",
      "[epoch=  9, iter=  600] loss: 0.882\n",
      "[epoch= 10, iter=  200] loss: 0.862\n",
      "[epoch= 10, iter=  400] loss: 0.848\n",
      "[epoch= 10, iter=  600] loss: 0.860\n",
      "[epoch= 11, iter=  200] loss: 0.817\n",
      "[epoch= 11, iter=  400] loss: 0.804\n",
      "[epoch= 11, iter=  600] loss: 0.814\n",
      "[epoch= 12, iter=  200] loss: 0.788\n",
      "[epoch= 12, iter=  400] loss: 0.770\n",
      "[epoch= 12, iter=  600] loss: 0.789\n",
      "[epoch= 13, iter=  200] loss: 0.751\n",
      "[epoch= 13, iter=  400] loss: 0.738\n",
      "[epoch= 13, iter=  600] loss: 0.754\n",
      "[epoch= 14, iter=  200] loss: 0.728\n",
      "[epoch= 14, iter=  400] loss: 0.711\n",
      "[epoch= 14, iter=  600] loss: 0.728\n",
      "[epoch= 15, iter=  200] loss: 0.684\n",
      "[epoch= 15, iter=  400] loss: 0.705\n",
      "[epoch= 15, iter=  600] loss: 0.713\n",
      "[epoch= 16, iter=  200] loss: 0.684\n",
      "[epoch= 16, iter=  400] loss: 0.672\n",
      "[epoch= 16, iter=  600] loss: 0.665\n",
      "[epoch= 17, iter=  200] loss: 0.645\n",
      "[epoch= 17, iter=  400] loss: 0.651\n",
      "[epoch= 17, iter=  600] loss: 0.665\n",
      "[epoch= 18, iter=  200] loss: 0.639\n",
      "[epoch= 18, iter=  400] loss: 0.639\n",
      "[epoch= 18, iter=  600] loss: 0.621\n",
      "[epoch= 19, iter=  200] loss: 0.612\n",
      "[epoch= 19, iter=  400] loss: 0.626\n",
      "[epoch= 19, iter=  600] loss: 0.598\n",
      "[epoch= 20, iter=  200] loss: 0.596\n",
      "[epoch= 20, iter=  400] loss: 0.596\n",
      "[epoch= 20, iter=  600] loss: 0.623\n",
      "[epoch= 21, iter=  200] loss: 0.572\n",
      "[epoch= 21, iter=  400] loss: 0.581\n",
      "[epoch= 21, iter=  600] loss: 0.579\n",
      "[epoch= 22, iter=  200] loss: 0.551\n",
      "[epoch= 22, iter=  400] loss: 0.585\n",
      "[epoch= 22, iter=  600] loss: 0.581\n",
      "[epoch= 23, iter=  200] loss: 0.549\n",
      "[epoch= 23, iter=  400] loss: 0.549\n",
      "[epoch= 23, iter=  600] loss: 0.561\n",
      "[epoch= 24, iter=  200] loss: 0.527\n",
      "[epoch= 24, iter=  400] loss: 0.574\n",
      "[epoch= 24, iter=  600] loss: 0.548\n",
      "[epoch= 25, iter=  200] loss: 0.518\n",
      "[epoch= 25, iter=  400] loss: 0.532\n",
      "[epoch= 25, iter=  600] loss: 0.540\n",
      "[epoch= 26, iter=  200] loss: 0.496\n",
      "[epoch= 26, iter=  400] loss: 0.522\n",
      "[epoch= 26, iter=  600] loss: 0.527\n",
      "[epoch= 27, iter=  200] loss: 0.503\n",
      "[epoch= 27, iter=  400] loss: 0.507\n",
      "[epoch= 27, iter=  600] loss: 0.505\n",
      "[epoch= 28, iter=  200] loss: 0.483\n",
      "[epoch= 28, iter=  400] loss: 0.499\n",
      "[epoch= 28, iter=  600] loss: 0.522\n",
      "[epoch= 29, iter=  200] loss: 0.491\n",
      "[epoch= 29, iter=  400] loss: 0.487\n",
      "[epoch= 29, iter=  600] loss: 0.498\n",
      "[epoch= 30, iter=  200] loss: 0.467\n",
      "[epoch= 30, iter=  400] loss: 0.478\n",
      "[epoch= 30, iter=  600] loss: 0.484\n",
      "[epoch= 31, iter=  200] loss: 0.486\n",
      "[epoch= 31, iter=  400] loss: 0.469\n",
      "[epoch= 31, iter=  600] loss: 0.468\n",
      "[epoch= 32, iter=  200] loss: 0.459\n",
      "[epoch= 32, iter=  400] loss: 0.473\n",
      "[epoch= 32, iter=  600] loss: 0.456\n",
      "[epoch= 33, iter=  200] loss: 0.440\n",
      "[epoch= 33, iter=  400] loss: 0.472\n",
      "[epoch= 33, iter=  600] loss: 0.470\n",
      "[epoch= 34, iter=  200] loss: 0.439\n",
      "[epoch= 34, iter=  400] loss: 0.455\n",
      "[epoch= 34, iter=  600] loss: 0.443\n",
      "[epoch= 35, iter=  200] loss: 0.441\n",
      "[epoch= 35, iter=  400] loss: 0.438\n",
      "[epoch= 35, iter=  600] loss: 0.447\n",
      "[epoch= 36, iter=  200] loss: 0.438\n",
      "[epoch= 36, iter=  400] loss: 0.443\n",
      "[epoch= 36, iter=  600] loss: 0.436\n",
      "[epoch= 37, iter=  200] loss: 0.428\n",
      "[epoch= 37, iter=  400] loss: 0.435\n",
      "[epoch= 37, iter=  600] loss: 0.427\n",
      "[epoch= 38, iter=  200] loss: 0.417\n",
      "[epoch= 38, iter=  400] loss: 0.425\n",
      "[epoch= 38, iter=  600] loss: 0.422\n",
      "[epoch= 39, iter=  200] loss: 0.406\n",
      "[epoch= 39, iter=  400] loss: 0.433\n",
      "[epoch= 39, iter=  600] loss: 0.404\n",
      "[epoch= 40, iter=  200] loss: 0.399\n",
      "[epoch= 40, iter=  400] loss: 0.396\n",
      "[epoch= 40, iter=  600] loss: 0.413\n",
      "[epoch= 41, iter=  200] loss: 0.400\n",
      "[epoch= 41, iter=  400] loss: 0.398\n",
      "[epoch= 41, iter=  600] loss: 0.412\n",
      "[epoch= 42, iter=  200] loss: 0.403\n",
      "[epoch= 42, iter=  400] loss: 0.395\n",
      "[epoch= 42, iter=  600] loss: 0.402\n",
      "[epoch= 43, iter=  200] loss: 0.381\n",
      "[epoch= 43, iter=  400] loss: 0.387\n",
      "[epoch= 43, iter=  600] loss: 0.389\n",
      "[epoch= 44, iter=  200] loss: 0.390\n",
      "[epoch= 44, iter=  400] loss: 0.401\n",
      "[epoch= 44, iter=  600] loss: 0.400\n",
      "[epoch= 45, iter=  200] loss: 0.362\n",
      "[epoch= 45, iter=  400] loss: 0.388\n",
      "[epoch= 45, iter=  600] loss: 0.384\n",
      "[epoch= 46, iter=  200] loss: 0.370\n",
      "[epoch= 46, iter=  400] loss: 0.387\n",
      "[epoch= 46, iter=  600] loss: 0.396\n",
      "[epoch= 47, iter=  200] loss: 0.364\n",
      "[epoch= 47, iter=  400] loss: 0.365\n",
      "[epoch= 47, iter=  600] loss: 0.375\n",
      "[epoch= 48, iter=  200] loss: 0.359\n",
      "[epoch= 48, iter=  400] loss: 0.366\n",
      "[epoch= 48, iter=  600] loss: 0.379\n",
      "[epoch= 49, iter=  200] loss: 0.364\n",
      "[epoch= 49, iter=  400] loss: 0.346\n",
      "[epoch= 49, iter=  600] loss: 0.369\n",
      "[epoch= 50, iter=  200] loss: 0.357\n",
      "[epoch= 50, iter=  400] loss: 0.366\n",
      "[epoch= 50, iter=  600] loss: 0.362\n",
      "[epoch= 51, iter=  200] loss: 0.353\n",
      "[epoch= 51, iter=  400] loss: 0.354\n",
      "[epoch= 51, iter=  600] loss: 0.351\n",
      "[epoch= 52, iter=  200] loss: 0.328\n",
      "[epoch= 52, iter=  400] loss: 0.342\n",
      "[epoch= 52, iter=  600] loss: 0.364\n",
      "[epoch= 53, iter=  200] loss: 0.340\n",
      "[epoch= 53, iter=  400] loss: 0.351\n",
      "[epoch= 53, iter=  600] loss: 0.348\n",
      "[epoch= 54, iter=  200] loss: 0.325\n",
      "[epoch= 54, iter=  400] loss: 0.339\n",
      "[epoch= 54, iter=  600] loss: 0.347\n",
      "[epoch= 55, iter=  200] loss: 0.344\n",
      "[epoch= 55, iter=  400] loss: 0.332\n",
      "[epoch= 55, iter=  600] loss: 0.334\n",
      "[epoch= 56, iter=  200] loss: 0.323\n",
      "[epoch= 56, iter=  400] loss: 0.328\n",
      "[epoch= 56, iter=  600] loss: 0.326\n",
      "[epoch= 57, iter=  200] loss: 0.318\n",
      "[epoch= 57, iter=  400] loss: 0.331\n",
      "[epoch= 57, iter=  600] loss: 0.321\n",
      "[epoch= 58, iter=  200] loss: 0.334\n",
      "[epoch= 58, iter=  400] loss: 0.331\n",
      "[epoch= 58, iter=  600] loss: 0.314\n",
      "[epoch= 59, iter=  200] loss: 0.328\n",
      "[epoch= 59, iter=  400] loss: 0.334\n",
      "[epoch= 59, iter=  600] loss: 0.314\n",
      "[epoch= 60, iter=  200] loss: 0.318\n",
      "[epoch= 60, iter=  400] loss: 0.327\n",
      "[epoch= 60, iter=  600] loss: 0.317\n",
      "[epoch= 61, iter=  200] loss: 0.309\n",
      "[epoch= 61, iter=  400] loss: 0.321\n",
      "[epoch= 61, iter=  600] loss: 0.312\n",
      "[epoch= 62, iter=  200] loss: 0.310\n",
      "[epoch= 62, iter=  400] loss: 0.312\n",
      "[epoch= 62, iter=  600] loss: 0.310\n",
      "[epoch= 63, iter=  200] loss: 0.297\n",
      "[epoch= 63, iter=  400] loss: 0.315\n",
      "[epoch= 63, iter=  600] loss: 0.313\n",
      "[epoch= 64, iter=  200] loss: 0.302\n",
      "[epoch= 64, iter=  400] loss: 0.302\n",
      "[epoch= 64, iter=  600] loss: 0.306\n",
      "[epoch= 65, iter=  200] loss: 0.303\n",
      "[epoch= 65, iter=  400] loss: 0.284\n",
      "[epoch= 65, iter=  600] loss: 0.311\n",
      "[epoch= 66, iter=  200] loss: 0.291\n",
      "[epoch= 66, iter=  400] loss: 0.298\n",
      "[epoch= 66, iter=  600] loss: 0.316\n",
      "[epoch= 67, iter=  200] loss: 0.304\n",
      "[epoch= 67, iter=  400] loss: 0.300\n",
      "[epoch= 67, iter=  600] loss: 0.301\n",
      "[epoch= 68, iter=  200] loss: 0.298\n",
      "[epoch= 68, iter=  400] loss: 0.295\n",
      "[epoch= 68, iter=  600] loss: 0.301\n",
      "[epoch= 69, iter=  200] loss: 0.293\n",
      "[epoch= 69, iter=  400] loss: 0.288\n",
      "[epoch= 69, iter=  600] loss: 0.293\n",
      "[epoch= 70, iter=  200] loss: 0.294\n",
      "[epoch= 70, iter=  400] loss: 0.290\n",
      "[epoch= 70, iter=  600] loss: 0.292\n",
      "[epoch= 71, iter=  200] loss: 0.289\n",
      "[epoch= 71, iter=  400] loss: 0.283\n",
      "[epoch= 71, iter=  600] loss: 0.280\n",
      "[epoch= 72, iter=  200] loss: 0.283\n",
      "[epoch= 72, iter=  400] loss: 0.297\n",
      "[epoch= 72, iter=  600] loss: 0.284\n",
      "[epoch= 73, iter=  200] loss: 0.284\n",
      "[epoch= 73, iter=  400] loss: 0.282\n",
      "[epoch= 73, iter=  600] loss: 0.282\n",
      "[epoch= 74, iter=  200] loss: 0.289\n",
      "[epoch= 74, iter=  400] loss: 0.278\n",
      "[epoch= 74, iter=  600] loss: 0.281\n",
      "[epoch= 75, iter=  200] loss: 0.274\n",
      "[epoch= 75, iter=  400] loss: 0.275\n",
      "[epoch= 75, iter=  600] loss: 0.280\n",
      "[epoch= 76, iter=  200] loss: 0.259\n",
      "[epoch= 76, iter=  400] loss: 0.297\n",
      "[epoch= 76, iter=  600] loss: 0.277\n",
      "[epoch= 77, iter=  200] loss: 0.269\n",
      "[epoch= 77, iter=  400] loss: 0.279\n",
      "[epoch= 77, iter=  600] loss: 0.268\n",
      "[epoch= 78, iter=  200] loss: 0.278\n",
      "[epoch= 78, iter=  400] loss: 0.263\n",
      "[epoch= 78, iter=  600] loss: 0.276\n",
      "[epoch= 79, iter=  200] loss: 0.256\n",
      "[epoch= 79, iter=  400] loss: 0.267\n",
      "[epoch= 79, iter=  600] loss: 0.279\n",
      "[epoch= 80, iter=  200] loss: 0.251\n",
      "[epoch= 80, iter=  400] loss: 0.278\n",
      "[epoch= 80, iter=  600] loss: 0.281\n",
      "[epoch= 81, iter=  200] loss: 0.260\n",
      "[epoch= 81, iter=  400] loss: 0.259\n",
      "[epoch= 81, iter=  600] loss: 0.267\n",
      "[epoch= 82, iter=  200] loss: 0.258\n",
      "[epoch= 82, iter=  400] loss: 0.265\n",
      "[epoch= 82, iter=  600] loss: 0.262\n",
      "[epoch= 83, iter=  200] loss: 0.274\n",
      "[epoch= 83, iter=  400] loss: 0.259\n",
      "[epoch= 83, iter=  600] loss: 0.275\n",
      "[epoch= 84, iter=  200] loss: 0.262\n",
      "[epoch= 84, iter=  400] loss: 0.253\n",
      "[epoch= 84, iter=  600] loss: 0.259\n",
      "[epoch= 85, iter=  200] loss: 0.244\n",
      "[epoch= 85, iter=  400] loss: 0.255\n",
      "[epoch= 85, iter=  600] loss: 0.261\n",
      "[epoch= 86, iter=  200] loss: 0.257\n",
      "[epoch= 86, iter=  400] loss: 0.251\n",
      "[epoch= 86, iter=  600] loss: 0.258\n",
      "[epoch= 87, iter=  200] loss: 0.232\n",
      "[epoch= 87, iter=  400] loss: 0.260\n",
      "[epoch= 87, iter=  600] loss: 0.268\n",
      "[epoch= 88, iter=  200] loss: 0.227\n",
      "[epoch= 88, iter=  400] loss: 0.245\n",
      "[epoch= 88, iter=  600] loss: 0.265\n",
      "[epoch= 89, iter=  200] loss: 0.233\n",
      "[epoch= 89, iter=  400] loss: 0.250\n",
      "[epoch= 89, iter=  600] loss: 0.268\n",
      "[epoch= 90, iter=  200] loss: 0.241\n",
      "[epoch= 90, iter=  400] loss: 0.247\n",
      "[epoch= 90, iter=  600] loss: 0.247\n",
      "[epoch= 91, iter=  200] loss: 0.249\n",
      "[epoch= 91, iter=  400] loss: 0.252\n",
      "[epoch= 91, iter=  600] loss: 0.253\n",
      "[epoch= 92, iter=  200] loss: 0.233\n",
      "[epoch= 92, iter=  400] loss: 0.247\n",
      "[epoch= 92, iter=  600] loss: 0.246\n",
      "[epoch= 93, iter=  200] loss: 0.219\n",
      "[epoch= 93, iter=  400] loss: 0.230\n",
      "[epoch= 93, iter=  600] loss: 0.241\n",
      "[epoch= 94, iter=  200] loss: 0.233\n",
      "[epoch= 94, iter=  400] loss: 0.226\n",
      "[epoch= 94, iter=  600] loss: 0.242\n",
      "[epoch= 95, iter=  200] loss: 0.234\n",
      "[epoch= 95, iter=  400] loss: 0.225\n",
      "[epoch= 95, iter=  600] loss: 0.248\n",
      "[epoch= 96, iter=  200] loss: 0.212\n",
      "[epoch= 96, iter=  400] loss: 0.247\n",
      "[epoch= 96, iter=  600] loss: 0.238\n",
      "[epoch= 97, iter=  200] loss: 0.243\n",
      "[epoch= 97, iter=  400] loss: 0.228\n",
      "[epoch= 97, iter=  600] loss: 0.223\n",
      "[epoch= 98, iter=  200] loss: 0.215\n",
      "[epoch= 98, iter=  400] loss: 0.231\n",
      "[epoch= 98, iter=  600] loss: 0.243\n",
      "[epoch= 99, iter=  200] loss: 0.230\n",
      "[epoch= 99, iter=  400] loss: 0.234\n",
      "[epoch= 99, iter=  600] loss: 0.234\n",
      "[epoch=100, iter=  200] loss: 0.220\n",
      "[epoch=100, iter=  400] loss: 0.216\n",
      "[epoch=100, iter=  600] loss: 0.234\n",
      "[epoch=101, iter=  200] loss: 0.227\n",
      "[epoch=101, iter=  400] loss: 0.234\n",
      "[epoch=101, iter=  600] loss: 0.225\n",
      "[epoch=102, iter=  200] loss: 0.224\n",
      "[epoch=102, iter=  400] loss: 0.241\n",
      "[epoch=102, iter=  600] loss: 0.234\n",
      "[epoch=103, iter=  200] loss: 0.209\n",
      "[epoch=103, iter=  400] loss: 0.223\n",
      "[epoch=103, iter=  600] loss: 0.218\n",
      "[epoch=104, iter=  200] loss: 0.216\n",
      "[epoch=104, iter=  400] loss: 0.215\n",
      "[epoch=104, iter=  600] loss: 0.235\n",
      "[epoch=105, iter=  200] loss: 0.218\n",
      "[epoch=105, iter=  400] loss: 0.222\n",
      "[epoch=105, iter=  600] loss: 0.220\n",
      "[epoch=106, iter=  200] loss: 0.219\n",
      "[epoch=106, iter=  400] loss: 0.216\n",
      "[epoch=106, iter=  600] loss: 0.226\n",
      "[epoch=107, iter=  200] loss: 0.213\n",
      "[epoch=107, iter=  400] loss: 0.222\n",
      "[epoch=107, iter=  600] loss: 0.215\n",
      "[epoch=108, iter=  200] loss: 0.209\n",
      "[epoch=108, iter=  400] loss: 0.216\n",
      "[epoch=108, iter=  600] loss: 0.220\n",
      "[epoch=109, iter=  200] loss: 0.204\n",
      "[epoch=109, iter=  400] loss: 0.209\n",
      "[epoch=109, iter=  600] loss: 0.216\n",
      "[epoch=110, iter=  200] loss: 0.232\n",
      "[epoch=110, iter=  400] loss: 0.224\n",
      "[epoch=110, iter=  600] loss: 0.224\n",
      "[epoch=111, iter=  200] loss: 0.214\n",
      "[epoch=111, iter=  400] loss: 0.210\n",
      "[epoch=111, iter=  600] loss: 0.215\n",
      "[epoch=112, iter=  200] loss: 0.203\n",
      "[epoch=112, iter=  400] loss: 0.225\n",
      "[epoch=112, iter=  600] loss: 0.229\n",
      "[epoch=113, iter=  200] loss: 0.212\n",
      "[epoch=113, iter=  400] loss: 0.214\n",
      "[epoch=113, iter=  600] loss: 0.200\n",
      "[epoch=114, iter=  200] loss: 0.209\n",
      "[epoch=114, iter=  400] loss: 0.208\n",
      "[epoch=114, iter=  600] loss: 0.225\n",
      "[epoch=115, iter=  200] loss: 0.201\n",
      "[epoch=115, iter=  400] loss: 0.201\n",
      "[epoch=115, iter=  600] loss: 0.210\n",
      "[epoch=116, iter=  200] loss: 0.199\n",
      "[epoch=116, iter=  400] loss: 0.213\n",
      "[epoch=116, iter=  600] loss: 0.212\n",
      "[epoch=117, iter=  200] loss: 0.220\n",
      "[epoch=117, iter=  400] loss: 0.208\n",
      "[epoch=117, iter=  600] loss: 0.200\n",
      "[epoch=118, iter=  200] loss: 0.202\n",
      "[epoch=118, iter=  400] loss: 0.214\n",
      "[epoch=118, iter=  600] loss: 0.215\n",
      "[epoch=119, iter=  200] loss: 0.207\n",
      "[epoch=119, iter=  400] loss: 0.218\n",
      "[epoch=119, iter=  600] loss: 0.199\n",
      "[epoch=120, iter=  200] loss: 0.200\n",
      "[epoch=120, iter=  400] loss: 0.192\n",
      "[epoch=120, iter=  600] loss: 0.199\n",
      "[epoch=121, iter=  200] loss: 0.214\n",
      "[epoch=121, iter=  400] loss: 0.201\n",
      "[epoch=121, iter=  600] loss: 0.203\n",
      "[epoch=122, iter=  200] loss: 0.204\n",
      "[epoch=122, iter=  400] loss: 0.202\n",
      "[epoch=122, iter=  600] loss: 0.207\n",
      "[epoch=123, iter=  200] loss: 0.203\n",
      "[epoch=123, iter=  400] loss: 0.198\n",
      "[epoch=123, iter=  600] loss: 0.216\n",
      "[epoch=124, iter=  200] loss: 0.192\n",
      "[epoch=124, iter=  400] loss: 0.200\n",
      "[epoch=124, iter=  600] loss: 0.203\n",
      "[epoch=125, iter=  200] loss: 0.198\n",
      "[epoch=125, iter=  400] loss: 0.214\n",
      "[epoch=125, iter=  600] loss: 0.199\n",
      "[epoch=126, iter=  200] loss: 0.199\n",
      "[epoch=126, iter=  400] loss: 0.201\n",
      "[epoch=126, iter=  600] loss: 0.210\n",
      "[epoch=127, iter=  200] loss: 0.181\n",
      "[epoch=127, iter=  400] loss: 0.184\n",
      "[epoch=127, iter=  600] loss: 0.198\n",
      "[epoch=128, iter=  200] loss: 0.186\n",
      "[epoch=128, iter=  400] loss: 0.205\n",
      "[epoch=128, iter=  600] loss: 0.199\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# the network optimizer\n",
    "optimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# training loop\n",
    "net.train()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (img, target) in enumerate(loader[\"train\"]):\n",
    "        img, target = img.to(device), target.to(device)\n",
    "\n",
    "        pred = net(img)\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_every == print_every - 1:\n",
    "            print(f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 86.12%\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for img, target in loader[\"test\"]:\n",
    "        img, target = img.to(device), target.to(device)\n",
    "        \n",
    "        # make prediction\n",
    "        pred = net(img)\n",
    "        \n",
    "        # accumulate\n",
    "        total += len(target)\n",
    "        correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
