#!/usr/bin/env python3
"""
æµ‹è¯•å¤šGPUè®­ç»ƒé…ç½®
"""

import torch
import torch.nn as nn
from models_imagenet import get_model

print("="*60)
print("å¤šGPUè®­ç»ƒé…ç½®æµ‹è¯•")
print("="*60)

# æ£€æµ‹GPU
if torch.cuda.is_available():
    gpu_count = torch.cuda.device_count()
    print(f"\nğŸ® æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU:")
    for i in range(gpu_count):
        print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"    æ˜¾å­˜: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB")
    device = torch.device("cuda:0")
    use_multi_gpu = gpu_count > 1
else:
    print("\nâŒ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPU")
    device = torch.device("cpu")
    use_multi_gpu = False
    gpu_count = 1

print(f"\nğŸ“ ä¸»è®¾å¤‡: {device}")
print(f"ğŸš€ å¤šGPUè®­ç»ƒ: {'âœ… å¯ç”¨' if use_multi_gpu else 'âŒ æœªå¯ç”¨ (å•å¡/CPU)'}")

# é…ç½®
batch_size = 64 * gpu_count
num_workers = 4 * gpu_count
num_classes = 200

print(f"\nâš™ï¸ é…ç½®:")
print(f"  Batch Size: {batch_size} ({'æ¯GPU '+str(batch_size//gpu_count) if use_multi_gpu else 'å•å¡'})")
print(f"  Num Workers: {num_workers}")

# åˆ›å»ºæµ‹è¯•æ¨¡å‹
print(f"\nğŸ—ï¸ åˆ›å»ºæµ‹è¯•æ¨¡å‹...")
model = get_model('baseline', num_classes)

# æ˜¾ç¤ºåŸå§‹æ¨¡å‹å‚æ•°é‡
param_count = sum(p.numel() for p in model.parameters()) / 1_000_000
print(f"  æ¨¡å‹å‚æ•°é‡: {param_count:.2f}M")

# å¤šGPUåŒ…è£…
if use_multi_gpu:
    print(f"  ğŸ”§ åŒ…è£…ä¸º DataParallel (ä½¿ç”¨ {gpu_count} ä¸ªGPU)")
    model = nn.DataParallel(model)
    print(f"  âœ… DataParallel è®¾å¤‡: {model.device_ids}")
else:
    print(f"  ğŸ“± å•è®¾å¤‡æ¨¡å¼")

model = model.to(device)

# æµ‹è¯•å‰å‘ä¼ æ’­
print(f"\nğŸ§ª æµ‹è¯•å‰å‘ä¼ æ’­...")
test_input = torch.randn(batch_size, 3, 64, 64).to(device)
print(f"  è¾“å…¥å½¢çŠ¶: {test_input.shape}")

try:
    with torch.no_grad():
        output = model(test_input)
    print(f"  è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼")
except Exception as e:
    print(f"  âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")

# æµ‹è¯•åå‘ä¼ æ’­
print(f"\nğŸ§ª æµ‹è¯•åå‘ä¼ æ’­...")
try:
    output = model(test_input)
    loss = output.sum()
    loss.backward()
    print(f"  âœ… åå‘ä¼ æ’­æˆåŠŸï¼")
except Exception as e:
    print(f"  âŒ åå‘ä¼ æ’­å¤±è´¥: {e}")

print("\n" + "="*60)
print("âœ… å¤šGPUé…ç½®æµ‹è¯•å®Œæˆï¼")
print("="*60)

